package com.aistarvision.autotracking;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.net.Socket;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;

import android.app.Activity;
import android.content.Context;
import android.content.Intent;
import android.content.res.Configuration;
import android.graphics.ImageFormat;
import android.graphics.Matrix;
import android.graphics.Point;
import android.graphics.Rect;
import android.graphics.RectF;
import android.graphics.SurfaceTexture;
import android.graphics.YuvImage;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.TotalCaptureResult;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.media.Image;
import android.media.ImageReader;
import android.os.Bundle;
import android.os.Handler;
import android.os.HandlerThread;
import android.util.Log;
import android.util.Size;
import android.view.Surface;
import android.view.TextureView;
import android.view.Window;
import android.view.WindowManager;

public class AutoTracking extends Activity {

	final static String TAG = "Camera2Activity";
	final static boolean DEBUG = true;
    /**
     * Camera state: Showing camera preview.
     */
    private static final int STATE_PREVIEW = 0;

    /**
     * Camera state: Waiting for the focus to be locked.
     */
    private static final int STATE_WAITING_LOCK = 1;

    /**
     * Camera state: Waiting for the exposure to be precapture state.
     */
    private static final int STATE_WAITING_PRECAPTURE = 2;

    /**
     * Camera state: Waiting for the exposure state to be something other than precapture.
     */
    private static final int STATE_WAITING_NON_PRECAPTURE = 3;

    /**
     * Camera state: Picture was taken.
     */
    private static final int STATE_PICTURE_TAKEN = 4;

	/**
	 * Max preview width that is guaranteed by Camera2 API
	 */
	private static final int MAX_PREVIEW_WIDTH = 1920;

	/**
	 * Max preview height that is guaranteed by Camera2 API
	 */
	private static final int MAX_PREVIEW_HEIGHT = 1080;

	AutoFitTextureView mTextureView;
	boolean isPreview = false; // 是否在浏览中
	private String ipname;
	private CameraManager mCameraManager;
	private String mCameraId;
	private ImageReader mImageReader;
	private CameraDevice mCameraDevice;
	   /**
     * {@link CaptureRequest.Builder} for the camera preview
     */
    private CaptureRequest.Builder mPreviewRequestBuilder;

    /**
     * {@link CaptureRequest} generated by {@link #mPreviewRequestBuilder}
     */
    private CaptureRequest mPreviewRequest;
	private int mState;
	private Semaphore mCameraOpenCloseLock = new Semaphore(1);
	private CameraCaptureSession mCaptureSession;
	private Handler mBackgroundHandler;
	private HandlerThread mBackgroundThread;
	private Size mPreviewSize;
	private boolean mFlashSupported;

    /**
     * This a callback object for the {@link ImageReader}. "onImageAvailable" will be called when a
     * still image is ready to be saved.
     */
	private final ImageReader.OnImageAvailableListener mOnImageAvailableListener = new ImageReader.OnImageAvailableListener() {

		@Override
		public void onImageAvailable(ImageReader reader) {
			if(DEBUG) Log.d(TAG, "ImageReader.OnImageAvailableListener : onImageAvailable");

			Image image = null;
			try {
				image = reader.acquireLatestImage();
//				if(DEBUG) Log.d(TAG, "image:"+image.getWidth()+ " , "+image.getHeight());
//				if (image != null) {
//
//					ByteBuffer buffer = image.getPlanes()[0].getBuffer();
//					byte[] bytes = new byte[buffer.remaining()];
//					buffer.get(bytes);
//					
//					YuvImage yuvimage = new YuvImage(bytes, ImageFormat.YUY2, image.getWidth(), image.getWidth(), null);
//					if (yuvimage != null) {
//						ByteArrayOutputStream outstream = new ByteArrayOutputStream();
//						yuvimage.compressToJpeg(new Rect(0, 0, image.getWidth(), image.getWidth()), 80, outstream);
//						outstream.flush();
//						// 启用线程将图像数据发送出去
//						Thread th = new MyThread(outstream, ipname);
//						th.start();
//					}
//				}
//
//			} catch (IOException e) {
//				// TODO Auto-generated catch block
//				e.printStackTrace();
			} finally {
				if (image != null) {
					image.close();
				}
			}
		}

	};
    
	private CameraDevice.StateCallback mStateCallback = new CameraDevice.StateCallback() {

		@Override
		public void onOpened(CameraDevice camera) {
			Log.d(TAG, "CameraDevice.StateCallback : onOpened");
            mCameraOpenCloseLock.release();
            mCameraDevice = camera;
            try {
				createCameraPriviewSession();
			} catch (CameraAccessException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}

		@Override
		public void onDisconnected(CameraDevice camera) {
			// TODO Auto-generated method stub
			Log.d(TAG, "CameraDevice.StateCallback : onDisconnected");
			
            mCameraOpenCloseLock.release();
            camera.close();
            mCameraDevice = null;
		}

		@Override
		public void onError(CameraDevice camera, int error) {
			// TODO Auto-generated method stub
			Log.d(TAG, "CameraDevice.StateCallback : onError");
			
            mCameraOpenCloseLock.release();
            camera.close();
            mCameraDevice = null;
            AutoTracking.this.finish();
		}
	};

    /**
     * A {@link CameraCaptureSession.CaptureCallback} that handles events related to JPEG capture.
     */
    private CameraCaptureSession.CaptureCallback mCaptureCallback
            = new CameraCaptureSession.CaptureCallback() {

        private void process(CaptureResult result) {
            switch (mState) {
                case STATE_PREVIEW: {
                    // We have nothing to do when the camera preview is working normally.
                    break;
                }
                case STATE_WAITING_LOCK: {
                    Integer afState = result.get(CaptureResult.CONTROL_AF_STATE);
                    if (afState == null) {
                       // captureStillPicture();
                    } else if (CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED == afState ||
                            CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED == afState) {
                        // CONTROL_AE_STATE can be null on some devices
                        Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                        if (aeState == null ||
                                aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED) {
                            mState = STATE_PICTURE_TAKEN;
                            //captureStillPicture();
                        } else {
                            //runPrecaptureSequence();
                        }
                    }
                    break;
                }
                case STATE_WAITING_PRECAPTURE: {
                    // CONTROL_AE_STATE can be null on some devices
                    Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState == null ||
                            aeState == CaptureResult.CONTROL_AE_STATE_PRECAPTURE ||
                            aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED) {
                        mState = STATE_WAITING_NON_PRECAPTURE;
                    }
                    break;
                }
                case STATE_WAITING_NON_PRECAPTURE: {
                    // CONTROL_AE_STATE can be null on some devices
                    Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState == null || aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE) {
                        mState = STATE_PICTURE_TAKEN;
                        //captureStillPicture();
                    }
                    break;
                }
            }
        }

        @Override
        public void onCaptureProgressed( CameraCaptureSession session,
                                         CaptureRequest request,
                                         CaptureResult partialResult) {
        	if(DEBUG) Log.d(TAG, "CameraCaptureSession.CaptureCallback : onCaptureProgressed");
        	
            process(partialResult);
        }

        @Override
        public void onCaptureCompleted(CameraCaptureSession session,
                                        CaptureRequest request,
                                        TotalCaptureResult result) {
        	if(DEBUG) Log.d(TAG, "CameraCaptureSession.CaptureCallback : onCaptureCompleted");
        	
            process(result);
        }

    };


	private final TextureView.SurfaceTextureListener mSurfaceTextureListener = new TextureView.SurfaceTextureListener() {

		@Override
		public void onSurfaceTextureAvailable(SurfaceTexture texture, int width, int height) {
			Log.d(TAG, "TextureView.SurfaceTextureListener : onSurfaceTextureAvailable");
			
			initCameraAndPreview(width, height);
		}

		@Override
		public void onSurfaceTextureSizeChanged(SurfaceTexture texture, int width, int height) {
			if(DEBUG) Log.d(TAG, "TextureView.SurfaceTextureListener : onSurfaceTextureSizeChanged:"+width+":"+height+",");
			
			configureTransform(width, height);
		}

		@Override
		public boolean onSurfaceTextureDestroyed(SurfaceTexture texture) {
			Log.d(TAG, "TextureView.SurfaceTextureListener : onSurfaceTextureDestroyed");
			return true;
		}

		@Override
		public void onSurfaceTextureUpdated(SurfaceTexture texture) {
			if(DEBUG) Log.d(TAG, "TextureView.SurfaceTextureListener : onSurfaceTextureUpdated");
		}

	};

	private CameraCaptureSession.StateCallback mSessionPreviewStateCallback = new CameraCaptureSession.StateCallback() {

		@Override
		public void onConfigured(CameraCaptureSession session) {
			Log.d(TAG, "CameraCaptureSession.StateCallback : onConfigured");
			
            if (null == mCameraDevice) {
                return;
            }

            // When the session is ready, we start displaying the preview.
            mCaptureSession = session;
            try {
                // Auto focus should be continuous for camera preview.
                mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE,
                        CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);
                // Flash is automatically enabled when necessary.
                setAutoFlash(mPreviewRequestBuilder);

                // Finally, we start displaying the camera preview.
                mPreviewRequest = mPreviewRequestBuilder.build();
                mCaptureSession.setRepeatingRequest(mPreviewRequest,
                        mCaptureCallback, mBackgroundHandler);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
		}

		@Override
		public void onConfigureFailed(CameraCaptureSession session) {
			// TODO Auto-generated method stub
			Log.d(TAG, "CameraCaptureSession.StateCallback : onConfigureFailed");
		}
	};

	@Override
	public void onCreate(Bundle savedInstanceState) {
		super.onCreate(savedInstanceState);
		// 设置全屏
		requestWindowFeature(Window.FEATURE_NO_TITLE);
		getWindow().setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN, WindowManager.LayoutParams.FLAG_FULLSCREEN);
		setContentView(R.layout.activity_camera2);

		// 获取IP地址
		Intent intent = getIntent();
		Bundle data = intent.getExtras();
		if(data != null){
			ipname = data.getString("ipname");
		}else{
			ipname = "192.168.1.102";
		}

		mCameraManager = (CameraManager) this.getSystemService(Context.CAMERA_SERVICE);
		mTextureView = (AutoFitTextureView) findViewById(R.id.textureview);

	}

	@Override
	protected void onResume() {
		// TODO Auto-generated method stub
		super.onResume();

		startBackgroundThread();
		if (mTextureView.isAvailable()) {
			initCameraAndPreview(mTextureView.getWidth(), mTextureView.getHeight());
		} else {
			mTextureView.setSurfaceTextureListener(mSurfaceTextureListener);
		}
	}

	@Override
	protected void onPause() {
		// TODO Auto-generated method stub
		super.onPause();
	}

	@Override
	protected void onDestroy() {
		// TODO Auto-generated method stub
		super.onDestroy();
	}

	/**
	 * Configures the necessary {@link android.graphics.Matrix} transformation
	 * to `mTextureView`. This method should be called after the camera preview
	 * size is determined in setUpCameraOutputs and also the size of
	 * `mTextureView` is fixed.
	 *
	 * @param viewWidth
	 *            The width of `mTextureView`
	 * @param viewHeight
	 *            The height of `mTextureView`
	 */
	private void configureTransform(int viewWidth, int viewHeight) {

		if (null == mTextureView || null == mPreviewSize) {
			return;
		}
		int rotation = this.getWindowManager().getDefaultDisplay().getRotation();
		Matrix matrix = new Matrix();
		RectF viewRect = new RectF(0, 0, viewWidth, viewHeight);
		RectF bufferRect = new RectF(0, 0, mPreviewSize.getHeight(), mPreviewSize.getWidth());
		float centerX = viewRect.centerX();
		float centerY = viewRect.centerY();
		if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
			bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY());
			matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL);
			float scale = Math.max((float) viewHeight / mPreviewSize.getHeight(),
					(float) viewWidth / mPreviewSize.getWidth());
			matrix.postScale(scale, scale, centerX, centerY);
			matrix.postRotate(90 * (rotation - 2), centerX, centerY);
		} else if (Surface.ROTATION_180 == rotation) {
			matrix.postRotate(180, centerX, centerY);
		}
		mTextureView.setTransform(matrix);
	}

	private void setAutoFlash(CaptureRequest.Builder requestBuilder) {
		if (mFlashSupported) {
			requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH);
		}
	}

	/**
	 * Starts a background thread and its {@link Handler}.
	 */
	private void startBackgroundThread() {
		mBackgroundThread = new HandlerThread("CameraBackground");
		mBackgroundThread.start();
		mBackgroundHandler = new Handler(mBackgroundThread.getLooper());
	}

	private void createCameraPriviewSession() throws CameraAccessException {
		Log.d(TAG, "createCameraPriviewSession");
		
        SurfaceTexture texture = mTextureView.getSurfaceTexture();
        assert texture != null;

        // We configure the size of default buffer to be the size of camera preview we want.
        texture.setDefaultBufferSize(mPreviewSize.getWidth(), mPreviewSize.getHeight());

        // This is the output Surface we need to start preview.
        Surface surface = new Surface(texture);

        // We set up a CaptureRequest.Builder with the output Surface.
        mPreviewRequestBuilder
                = mCameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        mPreviewRequestBuilder.addTarget(surface);
        
        mPreviewRequestBuilder.addTarget(mImageReader.getSurface());
        
		mState = STATE_PREVIEW;
		mCameraDevice.createCaptureSession(Arrays.asList(surface, mImageReader.getSurface()),
				mSessionPreviewStateCallback, mBackgroundHandler);
	}

	private void initCameraAndPreview(int width, int height) {
		Log.d(TAG, "initCameraAndPreview");

		setUpCameraOutputs(width, height);
		configureTransform(width, height);
        try {
            if (!mCameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw new RuntimeException("Time out waiting to lock camera opening.");
            }
            mCameraManager.openCamera(mCameraId, mStateCallback, mBackgroundHandler);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            throw new RuntimeException("Interrupted while trying to lock camera opening.", e);
        }
	}

	private void setUpCameraOutputs(int width, int height) {
		mCameraManager = (CameraManager) this.getSystemService(Context.CAMERA_SERVICE);
		try {
			for (String cameraId : mCameraManager.getCameraIdList()) {
				CameraCharacteristics characteristics = mCameraManager.getCameraCharacteristics(cameraId);

				// We don't use a front facing camera in this sample.
				Integer facing = characteristics.get(CameraCharacteristics.LENS_FACING);
				if (facing != null && facing == CameraCharacteristics.LENS_FACING_FRONT) {
					continue;
				}

				StreamConfigurationMap map = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);
				if (map == null) {
					continue;
				}

				// For still image captures, we use the largest available size.
				Size largest = Collections.max(Arrays.asList(map.getOutputSizes(ImageFormat.YUV_420_888)),
						new CompareSizesByArea());
				mImageReader = ImageReader.newInstance(largest.getWidth(), largest.getHeight(), ImageFormat.YUV_420_888,
						/* maxImages */2);
				mImageReader.setOnImageAvailableListener(mOnImageAvailableListener, mBackgroundHandler);

				// Find out if we need to swap dimension to get the preview size
				// relative to sensor
				// coordinate.
				int displayRotation = this.getWindowManager().getDefaultDisplay().getRotation();
				// noinspection ConstantConditions
				int mSensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);

				boolean swappedDimensions = false;
				switch (displayRotation) {
				case Surface.ROTATION_0:
				case Surface.ROTATION_180:
					if (mSensorOrientation == 90 || mSensorOrientation == 270) {
						swappedDimensions = true;
					}
					break;
				case Surface.ROTATION_90:
				case Surface.ROTATION_270:
					if (mSensorOrientation == 0 || mSensorOrientation == 180) {
						swappedDimensions = true;
					}
					break;
				default:
					Log.e(TAG, "Display rotation is invalid: " + displayRotation);
				}

				Point displaySize = new Point();
				this.getWindowManager().getDefaultDisplay().getSize(displaySize);
				int rotatedPreviewWidth = width;
				int rotatedPreviewHeight = height;
				int maxPreviewWidth = displaySize.x;
				int maxPreviewHeight = displaySize.y;

				if (swappedDimensions) {
					rotatedPreviewWidth = height;
					rotatedPreviewHeight = width;
					maxPreviewWidth = displaySize.y;
					maxPreviewHeight = displaySize.x;
				}

				if (maxPreviewWidth > MAX_PREVIEW_WIDTH) {
					maxPreviewWidth = MAX_PREVIEW_WIDTH;
				}

				if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) {
					maxPreviewHeight = MAX_PREVIEW_HEIGHT;
				}

				// Danger, W.R.! Attempting to use too large a preview size
				// could exceed the camera
				// bus' bandwidth limitation, resulting in gorgeous previews but
				// the storage of
				// garbage capture data.
				mPreviewSize = chooseOptimalSize(map.getOutputSizes(SurfaceTexture.class), rotatedPreviewWidth,
						rotatedPreviewHeight, maxPreviewWidth, maxPreviewHeight, largest);

				// We fit the aspect ratio of TextureView to the size of preview
				// we picked.
				int orientation = getResources().getConfiguration().orientation;
				 if (orientation == Configuration.ORIENTATION_LANDSCAPE) {
					mTextureView.setAspectRatio(mPreviewSize.getWidth(), mPreviewSize.getHeight());

				} else {
					mTextureView.setAspectRatio(mPreviewSize.getHeight(), mPreviewSize.getWidth());
				}

				// Check if the flash is supported.
				Boolean available = characteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE);
				mFlashSupported = available == null ? false : available;

				mCameraId = cameraId;
				return;
			}
		} catch (CameraAccessException e) {
			e.printStackTrace();
		} catch (NullPointerException e) {
			// Currently an NPE is thrown when the Camera2API is used but not
			// supported on the
			// device this code runs.

		}
	}

	private static Size chooseOptimalSize(Size[] choices, int textureViewWidth, int textureViewHeight, int maxWidth,
			int maxHeight, Size aspectRatio) {

		// Collect the supported resolutions that are at least as big as the
		// preview Surface
		List<Size> bigEnough = new ArrayList<Size>();
		// Collect the supported resolutions that are smaller than the preview
		// Surface
		List<Size> notBigEnough = new ArrayList<Size>();
		int w = aspectRatio.getWidth();
		int h = aspectRatio.getHeight();
		for (Size option : choices) {
			if (option.getWidth() <= maxWidth && option.getHeight() <= maxHeight
					&& option.getHeight() == option.getWidth() * h / w) {
				if (option.getWidth() >= textureViewWidth && option.getHeight() >= textureViewHeight) {
					bigEnough.add(option);
				} else {
					notBigEnough.add(option);
				}
			}
		}

		// Pick the smallest of those big enough. If there is no one big enough,
		// pick the
		// largest of those not big enough.
		if (bigEnough.size() > 0) {
			return Collections.min(bigEnough, new CompareSizesByArea());
		} else if (notBigEnough.size() > 0) {
			return Collections.max(notBigEnough, new CompareSizesByArea());
		} else {
			Log.e(TAG, "Couldn't find any suitable preview size");
			return choices[0];
		}
	}

	/**
	 * Compares two {@code Size}s based on their areas.
	 */
	static class CompareSizesByArea implements Comparator<Size> {

		@Override
		public int compare(Size lhs, Size rhs) {
			// We cast here to ensure the multiplications won't overflow
			return Long.signum((long) lhs.getWidth() * lhs.getHeight() - (long) rhs.getWidth() * rhs.getHeight());
		}

	}

	class MyThread extends Thread {
		private byte byteBuffer[] = new byte[1024];
		private OutputStream outsocket;
		private ByteArrayOutputStream myoutputstream;
		private String ipname;

		public MyThread(ByteArrayOutputStream myoutputstream, String ipname) {
			this.myoutputstream = myoutputstream;
			this.ipname = ipname;
			try {
				myoutputstream.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}

		public void run() {
			try {
				// 将图像数据通过Socket发送出去
				Socket tempSocket = new Socket(ipname, 6000);
				outsocket = tempSocket.getOutputStream();
				ByteArrayInputStream inputstream = new ByteArrayInputStream(myoutputstream.toByteArray());
				int amount;
				while ((amount = inputstream.read(byteBuffer)) != -1) {
					outsocket.write(byteBuffer, 0, amount);
				}
				myoutputstream.flush();
				myoutputstream.close();
				tempSocket.close();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
	}
}
